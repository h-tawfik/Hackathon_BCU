{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0731b900ebfb428c803e8f5020e7ceba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_21234500347f425786ce8c64a7a26746",
              "IPY_MODEL_93d487556730479db1e55bf4a9f04374",
              "IPY_MODEL_27da5acf18d84d5ba992bbe8a2f9d070"
            ],
            "layout": "IPY_MODEL_19ab7630cb234e26b6906ec24a1c6c4f"
          }
        },
        "21234500347f425786ce8c64a7a26746": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a31b0787962b40d5a8bfc0224c8f77b7",
            "placeholder": "​",
            "style": "IPY_MODEL_e347280ddd954150823868e1b15af693",
            "value": "Map: 100%"
          }
        },
        "93d487556730479db1e55bf4a9f04374": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_baacf1116cfb49009292d5bdd3541291",
            "max": 11975,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_71fe5df09f6a43dfa4e4606343aa98ad",
            "value": 11975
          }
        },
        "27da5acf18d84d5ba992bbe8a2f9d070": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d2b495e2e4ce4b2c99c8e6ef6efc26ad",
            "placeholder": "​",
            "style": "IPY_MODEL_d700031f666a4ac7ac2ed9334c8d02de",
            "value": " 11975/11975 [00:13&lt;00:00, 794.42 examples/s]"
          }
        },
        "19ab7630cb234e26b6906ec24a1c6c4f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a31b0787962b40d5a8bfc0224c8f77b7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e347280ddd954150823868e1b15af693": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "baacf1116cfb49009292d5bdd3541291": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "71fe5df09f6a43dfa4e4606343aa98ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d2b495e2e4ce4b2c99c8e6ef6efc26ad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d700031f666a4ac7ac2ed9334c8d02de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8tMvrdiDZ5My",
        "outputId": "a7d435a5-6026-466e-c955-1b7de80a0f84"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: peft in /usr/local/lib/python3.10/dist-packages (0.13.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from peft) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from peft) (24.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from peft) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from peft) (6.0.2)\n",
            "Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.10/dist-packages (from peft) (2.5.1+cu121)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from peft) (4.46.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from peft) (4.66.6)\n",
            "Requirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from peft) (1.1.1)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from peft) (0.4.5)\n",
            "Requirement already satisfied: huggingface-hub>=0.17.0 in /usr/local/lib/python3.10/dist-packages (from peft) (0.26.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.17.0->peft) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.17.0->peft) (2024.9.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.17.0->peft) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.17.0->peft) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (3.1.4)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.13.0->peft) (1.3.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers->peft) (2024.9.11)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers->peft) (0.20.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.13.0->peft) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.17.0->peft) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.17.0->peft) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.17.0->peft) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.17.0->peft) (2024.8.30)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (1.1.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.26.5)\n",
            "Requirement already satisfied: numpy<3.0.0,>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (24.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.4.5)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.5.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (2024.9.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (4.66.6)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.4)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.10.0->accelerate) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2024.8.30)\n",
            "Requirement already satisfied: bitsandbytes in /usr/local/lib/python3.10/dist-packages (0.45.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from bitsandbytes) (2.5.1+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from bitsandbytes) (1.26.4)\n",
            "Requirement already satisfied: typing_extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from bitsandbytes) (4.12.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (3.16.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (2024.9.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch->bitsandbytes) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->bitsandbytes) (3.0.2)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (3.2.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.16.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.6)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.9.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.11.10)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.26.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.8.30)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install peft\n",
        "!pip install accelerate\n",
        "!pip install bitsandbytes  # for 8-bit optimization if needed\n",
        "!pip install datasets\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hH1kvhFKYl9B",
        "outputId": "dab0375b-28b9-43c0-898e-25aad422083a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, TrainingArguments, Trainer, get_scheduler\n",
        "from datasets import Dataset\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from peft import LoraConfig, get_peft_model, TaskType\n",
        "from typing import List, Dict\n",
        "\n",
        "# Ensure reproducibility\n",
        "np.random.seed(42)\n",
        "torch.manual_seed(42)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L_3yuaP6aCkW",
        "outputId": "fe4573ae-034a-4b34-8424-fcb1faf03092"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7d087b279950>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_question_difficulty(text: str) -> float:\n",
        "    \"\"\"\n",
        "    Calculate question difficulty based on various heuristics.\n",
        "    \"\"\"\n",
        "    # Simple heuristics for difficulty scoring\n",
        "    difficulty_score = 0\n",
        "\n",
        "    # Length-based complexity\n",
        "    difficulty_score += len(text.split()) * 0.01\n",
        "\n",
        "    # Keyword-based complexity\n",
        "    complex_keywords = ['analyze', 'evaluate', 'explain', 'compare', 'contrast', 'predict']\n",
        "    difficulty_score += sum(word in text.lower() for word in complex_keywords) * 0.5\n",
        "\n",
        "    # Number of technical terms (can be expanded)\n",
        "    technical_terms = ['algorithm', 'theory', 'principle', 'methodology']\n",
        "    difficulty_score += sum(term in text.lower() for term in technical_terms) * 0.3\n",
        "\n",
        "    return difficulty_score"
      ],
      "metadata": {
        "id": "AbN__G7dbmTb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_data(data_path: str, tokenizer) -> Dataset:\n",
        "    \"\"\"\n",
        "    Load and preprocess the dataset with proper labels for language modeling.\n",
        "    \"\"\"\n",
        "    df = pd.read_csv(data_path,encoding=\"ISO-8859-1\")\n",
        "\n",
        "    # Format input text\n",
        "    df[\"input_text\"] = df.apply(\n",
        "        lambda x: f\"Question: {x['prompt']}\\nA) {x['A']}\\nB) {x['B']}\\nC) {x['C']}\\nD) {x['D']}\\nE) {x['E']}\\nAnswer: {x['answer']}\\n\",\n",
        "        axis=1\n",
        "    )\n",
        "\n",
        "    # Tokenize the dataset\n",
        "    def tokenize_function(examples):\n",
        "        tokenized = tokenizer(\n",
        "            examples[\"input_text\"],\n",
        "            truncation=True,\n",
        "            padding='max_length',\n",
        "            max_length=512,\n",
        "            return_tensors=None\n",
        "        )\n",
        "\n",
        "        # Set labels for causal language modeling\n",
        "        tokenized[\"labels\"] = tokenized[\"input_ids\"].copy()\n",
        "        return tokenized\n",
        "\n",
        "    # Convert to Hugging Face Dataset and tokenize\n",
        "    dataset = Dataset.from_pandas(df[[\"input_text\"]])\n",
        "    tokenized_dataset = dataset.map(\n",
        "        tokenize_function,\n",
        "        batched=True,\n",
        "        remove_columns=dataset.column_names\n",
        "    )\n",
        "\n",
        "    return tokenized_dataset"
      ],
      "metadata": {
        "id": "_4Dp0J2xbjlR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_curriculum_dataloaders(tokenized_dataset: Dataset, num_stages: int = 3):\n",
        "    \"\"\"\n",
        "    Create curriculum learning stages based on sequence length instead of difficulty score.\n",
        "    \"\"\"\n",
        "    # Use sequence length as a proxy for difficulty\n",
        "    sequence_lengths = [sum(attention_mask) for attention_mask in tokenized_dataset['attention_mask']]\n",
        "\n",
        "    # Create a new dataset with sequence lengths\n",
        "    indexed_dataset = Dataset.from_dict({\n",
        "        'index': range(len(tokenized_dataset)),\n",
        "        'length': sequence_lengths\n",
        "    })\n",
        "\n",
        "    # Sort by sequence length\n",
        "    sorted_indices = sorted(range(len(sequence_lengths)), key=lambda k: sequence_lengths[k])\n",
        "\n",
        "    # Split into stages\n",
        "    stage_size = len(sorted_indices) // num_stages\n",
        "    stages = []\n",
        "\n",
        "    for i in range(num_stages):\n",
        "        start_idx = i * stage_size\n",
        "        end_idx = (i + 1) * stage_size if i < num_stages - 1 else len(sorted_indices)\n",
        "        stage_indices = sorted_indices[start_idx:end_idx]\n",
        "        stages.append(tokenized_dataset.select(stage_indices))\n",
        "\n",
        "    return stages"
      ],
      "metadata": {
        "id": "zFsQahm8bhxo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fine_tune_model(\n",
        "    dataset: Dataset,\n",
        "    model_name: str = \"EleutherAI/gpt-neo-1.3B\",\n",
        "    #model_name: str = \"mistralai/Mistral-7B-v0.1\",\n",
        "    output_dir: str = \"fine_tuned_model\"\n",
        ") -> tuple:\n",
        "    os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
        "\n",
        "    # Initialize tokenizer\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "    if tokenizer.pad_token is None:\n",
        "        tokenizer.pad_token = tokenizer.eos_token\n",
        "        tokenizer.pad_token_id = tokenizer.eos_token_id\n",
        "\n",
        "    # Load model\n",
        "    model = AutoModelForCausalLM.from_pretrained(\n",
        "        model_name,\n",
        "        torch_dtype=torch.float16,\n",
        "        low_cpu_mem_usage=True,\n",
        "        use_cache=False\n",
        "    ).to('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "    # Configure LoRA\n",
        "    lora_config = LoraConfig(\n",
        "        r=8,\n",
        "        lora_alpha=16,\n",
        "        target_modules=['q_proj', 'v_proj', 'k_proj'],\n",
        "        lora_dropout=0.05,\n",
        "        bias=\"none\",\n",
        "        task_type=TaskType.CAUSAL_LM,\n",
        "        inference_mode=False\n",
        "    )\n",
        "\n",
        "    # Get PEFT model\n",
        "    model = get_peft_model(model, lora_config)\n",
        "\n",
        "    # Training arguments\n",
        "    training_args = TrainingArguments(\n",
        "        output_dir=output_dir,\n",
        "        eval_strategy=\"steps\",\n",
        "        eval_steps=100,\n",
        "        learning_rate=2e-4,\n",
        "        per_device_train_batch_size=1,\n",
        "        gradient_accumulation_steps=8,\n",
        "        num_train_epochs=1,\n",
        "        weight_decay=0.05,\n",
        "        save_steps=500,\n",
        "        save_total_limit=2,\n",
        "        logging_dir=\"./logs\",\n",
        "        logging_steps=10,\n",
        "        report_to=\"none\",\n",
        "        fp16=True,\n",
        "        warmup_steps=100,\n",
        "        dataloader_num_workers=0,\n",
        "        remove_unused_columns=True,  # Changed to True\n",
        "        no_cuda=False\n",
        "    )\n",
        "\n",
        "    # Create curriculum stages\n",
        "    stages = create_curriculum_dataloaders(dataset, num_stages=3)\n",
        "\n",
        "    # Custom data collator\n",
        "    from transformers import default_data_collator\n",
        "\n",
        "    # Train through curriculum stages\n",
        "    for stage_idx, stage_dataset in enumerate(stages):\n",
        "        print(f\"\\nTraining on curriculum stage {stage_idx + 1}/{len(stages)}\")\n",
        "\n",
        "        # Split into train and eval\n",
        "        train_size = int(0.8 * len(stage_dataset))\n",
        "        train_dataset = stage_dataset.select(range(train_size))\n",
        "        eval_dataset = stage_dataset.select(range(train_size, len(stage_dataset)))\n",
        "\n",
        "        trainer = Trainer(\n",
        "            model=model,\n",
        "            args=training_args,\n",
        "            train_dataset=train_dataset,\n",
        "            eval_dataset=eval_dataset,\n",
        "            data_collator=default_data_collator,  # Added data collator\n",
        "        )\n",
        "\n",
        "        trainer.train()\n",
        "\n",
        "        eval_results = trainer.evaluate()\n",
        "        print(f\"Stage {stage_idx + 1} evaluation results:\", eval_results)\n",
        "\n",
        "    model.save_pretrained(output_dir)\n",
        "    tokenizer.save_pretrained(output_dir)\n",
        "\n",
        "    return model, tokenizer"
      ],
      "metadata": {
        "id": "a-nZOc9sbeXY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_answer(question: str, model, tokenizer) -> str:\n",
        "    \"\"\"\n",
        "    Generate an answer using the fine-tuned model.\n",
        "    \"\"\"\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    inputs = tokenizer.encode(question, return_tensors=\"pt\", truncation=True).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model.generate(\n",
        "            inputs,\n",
        "            max_length=200,\n",
        "            num_return_sequences=1,\n",
        "            temperature=0.7,\n",
        "            top_p=0.9,\n",
        "        )\n",
        "\n",
        "    return tokenizer.decode(outputs[0], skip_special_tokens=True).strip()\n"
      ],
      "metadata": {
        "id": "7S2ybwfhbX7z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_selected_option(generated_answer: str, options: List[str]) -> str:\n",
        "    \"\"\"\n",
        "    Extract the selected option from the generated answer.\n",
        "    \"\"\"\n",
        "    for option in options:\n",
        "        if option in generated_answer:\n",
        "            return option\n",
        "    return \"N/A\"\n"
      ],
      "metadata": {
        "id": "oWSzBL_0bV7u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    # Paths and configurations\n",
        "    dataset_path = \"/content/drive/MyDrive/data/Hackathon_KB_updated.csv\"\n",
        "    fine_tuned_dir = \"fine_tuned_model\"\n",
        "\n",
        "    # Initialize tokenizer first\n",
        "    tokenizer = AutoTokenizer.from_pretrained(\"EleutherAI/gpt-neo-1.3B\")\n",
        "    if tokenizer.pad_token is None:\n",
        "        tokenizer.pad_token = tokenizer.eos_token\n",
        "        tokenizer.pad_token_id = tokenizer.eos_token_id\n",
        "\n",
        "    # Prepare dataset and fine-tune model\n",
        "    print(\"Preparing dataset...\")\n",
        "    dataset = prepare_data(dataset_path, tokenizer)  # Pass tokenizer to prepare_data\n",
        "\n",
        "    print(\"Fine-tuning model...\")\n",
        "    model, tokenizer = fine_tune_model(dataset, output_dir=fine_tuned_dir)\n",
        "\n",
        "\n",
        "\n",
        "    print(\"Processing test questions...\")\n",
        "    df = pd.read_csv(\"/content/drive/MyDrive/Hackathon_Question_set (1).csv\")\n",
        "\n",
        "    results = []\n",
        "    for idx, row in df.iterrows():\n",
        "        question = row['Question']\n",
        "        options = [opt.strip() for opt in question.split() if opt.endswith(\")\")]\n",
        "        generated_answer = generate_answer(question, model, tokenizer)\n",
        "        selected_option = extract_selected_option(generated_answer, options)\n",
        "        results.append({\"Number\": row['Number'], \"Answer\": selected_option})\n",
        "\n",
        "        # Progress update\n",
        "        if (idx + 1) % 10 == 0:\n",
        "            print(f\"Processed {idx + 1}/{len(df)} questions\")\n",
        "\n",
        "    # Save results\n",
        "    results_df = pd.DataFrame(results)\n",
        "    results_df.to_csv(\"answers.csv\", index=False)\n",
        "    print(\"Results saved to answers.csv\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 706,
          "referenced_widgets": [
            "0731b900ebfb428c803e8f5020e7ceba",
            "21234500347f425786ce8c64a7a26746",
            "93d487556730479db1e55bf4a9f04374",
            "27da5acf18d84d5ba992bbe8a2f9d070",
            "19ab7630cb234e26b6906ec24a1c6c4f",
            "a31b0787962b40d5a8bfc0224c8f77b7",
            "e347280ddd954150823868e1b15af693",
            "baacf1116cfb49009292d5bdd3541291",
            "71fe5df09f6a43dfa4e4606343aa98ad",
            "d2b495e2e4ce4b2c99c8e6ef6efc26ad",
            "d700031f666a4ac7ac2ed9334c8d02de"
          ]
        },
        "id": "wfd740nebSdg",
        "outputId": "2ebd8b9b-85d2-4554-dc5d-1bbeed59085d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Preparing dataset...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/11975 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0731b900ebfb428c803e8f5020e7ceba"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tuning model...\n",
            "\n",
            "Training on curriculum stage 1/3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='399' max='399' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [399/399 20:54, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>0.122000</td>\n",
              "      <td>0.151664</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.104300</td>\n",
              "      <td>0.147720</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>0.088000</td>\n",
              "      <td>0.147618</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='100' max='100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [100/100 01:40]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stage 1 evaluation results: {'eval_loss': 0.146981343626976, 'eval_runtime': 101.2136, 'eval_samples_per_second': 7.894, 'eval_steps_per_second': 0.988, 'epoch': 1.0}\n",
            "\n",
            "Training on curriculum stage 2/3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='399' max='399' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [399/399 20:59, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>0.223600</td>\n",
              "      <td>0.306284</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.218600</td>\n",
              "      <td>0.302203</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>0.217800</td>\n",
              "      <td>0.298856</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='100' max='100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [100/100 01:40]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stage 2 evaluation results: {'eval_loss': 0.2976418137550354, 'eval_runtime': 101.5432, 'eval_samples_per_second': 7.869, 'eval_steps_per_second': 0.985, 'epoch': 1.0}\n",
            "\n",
            "Training on curriculum stage 3/3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='201' max='399' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [201/399 09:41 < 09:38, 0.34 it/s, Epoch 0.50/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>0.361400</td>\n",
              "      <td>0.513434</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>\n",
              "    <div>\n",
              "      \n",
              "      <progress value='83' max='100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 83/100 01:24 < 00:17, 0.97 it/s]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "    print(\"Processing test questions...\")\n",
        "    df = pd.read_csv(\"/content/Hackathon_Question_set_sample22.csv\")\n",
        "\n",
        "    results = []\n",
        "    for idx, row in df.iterrows():\n",
        "        question = row['Question']\n",
        "        options = [opt.strip() for opt in question.split() if opt.endswith(\")\")]\n",
        "        generated_answer = generate_answer(question, model, tokenizer)\n",
        "        selected_option = extract_selected_option(generated_answer, options)\n",
        "        results.append({\"Number\": row['Number'], \"Answer\": selected_option})\n",
        "\n",
        "        # Progress update\n",
        "        if (idx + 1) % 10 == 0:\n",
        "            print(f\"Processed {idx + 1}/{len(df)} questions\")\n",
        "\n",
        "    # Save results\n",
        "    results_df = pd.DataFrame(results)\n",
        "    results_df.to_csv(\"answers.csv\", index=False)\n",
        "    print(\"Results saved to answers.csv\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "41l7A5IQ20F4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}